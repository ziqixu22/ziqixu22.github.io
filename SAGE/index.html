<!DOCTYPE html>

<html lang="en">
    <head>
        <meta charset="UTF-8">


        <meta name="description" content="Project website for SAGE">
        <meta name="author" content="Haoran Geng">
        <meta name="viewport" content="width=device-width, initial-scale=1">



        
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300;0,400;0,500;0,600;0,700;0,800;1,300;1,400;1,500;1,600;1,700;1,800&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel="stylesheet">
        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" type="text/css" href="style.css?cache=77333914184988801948">
        <link rel="icon" href="icons/sage_icon.png">

        <title>SAGE</title>
        <link rel="stylesheet" href="style.css">
    </head>

    <style>
        a {
            color: #B1040E;
        }

        a:hover {
            color: #820000;
            text-decoration: underline;
        }

        .body_text {
            color: rgb(46,45,41);
            font-family: 'Open Sans', sans-serif;
            font-weight: 300;
            line-height: 1.9rem;
            font-size: 1.1rem;
        }

        .text_title {
            color: rgb(46,45,41);
            font-family: 'Open Sans', sans-serif;
            font-weight: 500;
            line-height: 3rem;
            font-size: 2.2rem;
            padding-top: 20px;
        }

        .text_venue {
            font-family: 'Open Sans', sans-serif;
            font-weight: 500;
            line-height: 2.0rem;
            font-size: 1.5rem;
            color: rgb(77, 79, 83);
        }

        .text_author {
            font-family: 'Open Sans', sans-serif;
            font-weight: 400;
            line-height: 1.5rem;
            font-size: 1.1rem;
            color: rgb(77, 79, 83);
        }

        .text_resource {
            font-family: 'Open Sans', sans-serif;
            font-weight: 400;
            line-height: 1.5rem;
            font-size: 1.0rem;
            color: rgb(77, 79, 83);
        }

        .text_header {
            font-family: 'Open Sans', sans-serif;
            font-weight: 400;
            line-height: 2.5rem;
            font-size: 2.0rem;
            margin-top: 0.4rem;
            color: rgb(140, 21, 21);
        }

        .figure_caption {
            font-family: 'Open Sans', sans-serif;
            font-weight: 400;
            line-height: 1.8rem;
            font-size: 1.2rem;
            color: rgb(77, 79, 83);
        }

        .text_reference {
            font-family: 'Open Sans', sans-serif;
            text-align: left;
            font-size: 0.7em;
            color: rgb(77, 79, 83);
        }

        .text_ack {
            font-family: 'Open Sans', sans-serif;
            text-align: center;
            font-size: 0.7em;
            color: rgb(140, 21, 21);
        }

        .teaser_grid {
            display: grid;
            grid-template-columns: 33% 33% 33%;
            grid-template-rows: 1fr;
            justify-content: center;
            grid-auto-flow: row;
        }

        .teaser_fig {
            max-width: 99%;
            display: block;
            margin-left: auto;
  			margin-right: auto;

        }

        .icons {
            height: 3.5em;
        }


        .big_figure {
            max-width: 100%;
            display: block;
            margin: 1em auto 1em;
        }

        .median_figure {
            max-width: 75%;
            display: block;
            margin: 1em auto 1em;
        }

        .color_switch {
            background-color: rgb(255, 255, 255);
        }

        .teaser_item {
            text-align: center;
        }

        .table_title {
            font-family: 'Open Sans', sans-serif;
            font-weight: 700;
            font-size: 1.25rem;
            color: rgb(77, 79, 83);
            text-align: center;
        }

        .table_head {
            font-family: 'Open Sans', sans-serif;
            font-weight: 600;
            font-size: 1.1rem;
            color: rgb(77, 79, 83);
            text-align: center;
        }

        .table_elem {
            font-family: 'Open Sans', sans-serif;
            font-weight: 300;
            font-size: 1.0rem;
            color: rgb(77, 79, 83);
            text-align: center;
            align-self: center;
        }

        .table_emph {
            font-weight: 700;
        }

        .jumbotron {
            max-width: 900px;
            margin: 0 auto;
            padding: 20px 4px 20px 4px;
        }
        .jumbotron > .title {
            font-size: 18pt;
            color: #414446;
            clear: both;
            text-align: center;
        }

        .carousel-item {
            text-align: center;
        }
        .carousel-caption {
            height: 15%;
            background: rgba(230, 230, 230, 0.9);
        }

    </style>

    <body>
    <section>
    <div class="container">
        <div class="row" id="title">
            <p class="col text-center mt-4 text_title">
                SAGE&#127807;: Bridging Semantic and Actionable Parts for Generalizable Articulated-Object Manipulation under Language Instructions
            </p>
        </div>

        <div class="row" id="venue">
            <p class="col text-center text_venue">   
            </p>
        </div>

        
        <div class="row" id="authors">
            <div class="col-md-12 text-center mt-2 text_author">
                <ul class="list-inline">
                    <li class="list-inline-item mx-2">
                        <a href="https://geng-haoran.github.io/">
                            <p>Haoran Geng<sup>&#127794;&#127982;</sup>*</p>
                        </a>
                    </li>
                    <li class="list-inline-item mx-2">
                        <a href="http://wei.songl.in/">
                            <p>Songlin Wei<sup>&#127982;&#128167;</sup>*</p>
                        </a>
                    </li>
                    <li class="list-inline-item mx-2">
                        <a href="https://cs.stanford.edu/~congyue/">
                            <p>Congyue Deng<sup>&#127794;</sup></p>
                        </a>
                    </li>
                    <li class="list-inline-item mx-2">
                        <a href="https://cs.stanford.edu/people/bshen88/">
                            <p>Bokui Shen<sup>&#127794;</sup></p>
                        </a>
                    </li>
                    <li class="list-inline-item mx-2">
                        <a href="https://geng-haoran.github.io/">
                            <p>He Wang<sup>&#127982;&#128167;+</sup></p>
                        </a>
                    </li>
                    <li class="list-inline-item mx-2">
                        <a href="https://geometry.stanford.edu/member/guibas/index.html">
                            <p>Leonidas Guibas<sup>&#127794;+</sup></p>
                        </a>
                    </li>
                    <br>
                    (*equal contribution, <sup>+</sup>equal advising)
                </ul>
                <ul class="list-inline" style="margin-top: 1rem">
                    <li class="list-inline-item mx-3">
                        <p><sup>&#127794;</sup>Stanford University</p>
                    </li>
                    <li class="list-inline-item mx-3">
                        <p><sup>&#127982;</sup>Peking University</p>
                    </li>
                    <li class="list-inline-item mx-3">
                        <p><sup>&#128167;</sup>Beijing Academy of Artificial Intelligence</p>
                    </li>
                </ul>
            </div>
        </div>
        

        <div class="row" id="resources">
            <div class="col text-center text_resource">
                <ul class="list-inline">
                    <li class="list-inline-item mx-4">
                        <a href="">
                            <img src="icons/paper_icon.png" class="icons">
                            <p>Paper</p>
                        </a>
                    </li>
                    <li class="list-inline-item mx-4">
                            <a href="https://youtu.be/DnFmsNzzbWY">
                            <img src="icons/youtube_icon.png" class="icons">
                            <p>Video</p>
                            </a>
                    </li>
                    <li class="list-inline-item mx-4">
                        <a href="https://github.com/geng-haoran/SAGE">
                            <img src="icons/github_icon.png" class="icons">
                            <p>Code</p>
                        </a>
                    </li>
                </ul>
            </div>
        </div>
    </div>

    </section>

    <section class="color_switch">
        <div class="container">
        <div class="jumbotron" id="home">
            <div id="carouselExampleDark" class="carousel carousel-dark slide" data-bs-ride="carousel">
              <div class="carousel-indicators">
                <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="0" class="active" aria-current="true" aria-label="Slide 1"></button>
                <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="1" aria-label="Slide 2"></button>
                <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="2" aria-label="Slide 3"></button>
                <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="3" aria-label="Slide 4"></button>
                <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="4" aria-label="Slide 5"></button>
              </div>
              <div class="carousel-inner">
                <div class="carousel-item active" data-bs-interval="4000">
                  <video autoplay muted loop height="400">
                    <source src="videos/press_blender.mp4" type="video/mp4">
                  </video>
                  <div class="carousel-caption d-none d-md-block">
                    <h5>"Turn on the blender."</h5>
                  </div>
                </div>
                <div class="carousel-item" data-bs-interval="16000">
                  <video autoplay muted loop height="400">
                    <source src="videos/long_horizon_microwave.mp4" type="video/mp4">
                  </video>
                  <div class="carousel-caption d-none d-md-block">
                    <h5>"Open the microwave."</h5>
                  </div>
                </div>
                <div class="carousel-item" data-bs-interval="10000">
                  <video autoplay muted loop height="400">
                    <source src="videos/press_button_revolve.mp4" type="video/mp4">
                  </video>
                  <div class="carousel-caption d-none d-md-block">
                    <h5>"Turn on/off the machine."</h5>
                  </div>
                </div>
                <div class="carousel-item" data-bs-interval="6000">
                  <video autoplay muted loop height="400">
                    <source src="videos/lift_lid_big.mp4" type="video/mp4">
                  </video>
                  <div class="carousel-caption d-none d-md-block">
                    <h5>"Lift the pod's lid."</h5>
                  </div>
                </div>
                <div class="carousel-item" data-bs-interval="8000">
                  <video autoplay muted loop height="400">
                    <source src="videos/pull_drawer.mp4" type="video/mp4">
                  </video>
                  <div class="carousel-caption d-none d-md-block">
                    <h5>"Slide the drawer open."</h5>
                  </div>
                </div>
              </div>
              <button class="carousel-control-prev" type="button" data-bs-target="#carouselExampleDark" data-bs-slide="prev">
                <span class="carousel-control-prev-icon" aria-hidden="true"></span>
                <span class="visually-hidden">Previous</span>
              </button>
              <button class="carousel-control-next" type="button" data-bs-target="#carouselExampleDark" data-bs-slide="next">
                <span class="carousel-control-next-icon" aria-hidden="true"></span>
                <span class="visually-hidden">Next</span>
              </button>
            </div>
        </div>
        </div>
        <br><br>
    </section>

    <section class="color_switch">
        <div class="container">
        <div class="row" id="abstract">
            <div class="col my-3">
                <img src="images/teaser.png" class="teaser_fig">
                <br><br>

                <p class="text_header">
                    Summary
                </p>

                <p class="body_text">
                    <ul>
                    	<li class="body_text">We introduce a novel perspective of bridging semantic and actionable parts and construct a robot system for generalizable manipulation of articulated objects.</li>
                    	<li class="body_text">We explore the idea of joining the forces of general-purpose large models and domain-specific models extensively throughout our pipeline from scene understanding, part perception, to manipulation.</li>
                    	<li class="body_text">We demonstrate our strong generalizability on a variety of different objects under diverse language instructions in both simulation environments and on real robots.</li>
                    	<li class="body_text">We also provide a new benchmark for articulated-object manipulation including evaluations of scene descriptions, part perceptions, and manipulation policies.</li>
                    </ul>
                </p>
            </div>
        </div>
        </div>
    </section>


    <section>
        <div class="container">
        <div class="row">
            <div class="col my-3">
                <p class="text_header">
                    Video
                </p>
                <div class="text-center mb-4">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com/embed/DnFmsNzzbWY?si=nFb6igz3Vf7kHDQ6" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>

                    </div>
                </div>
            </div>
        </div>
        </div>
    </section>


    <section class="color_switch">
        <div class="container">
        <div class="row" id="abstract">
            <div class="col my-3">
                <p class="text_header">
                    Context-Aware Instruction Interpretation
                </p>
                
                <p class="body_text">
                    With instruction and observation (RGBD image) as input, the interpreter first generates a scene description with VLM (Bard) and GAPartNet. Then LLM (GPT-4) takes both instruction and scene description as input and generates semantic parts and action programs. Optionally, we can input a specific user manual and LLM will generate a target actionable part.
                </p>
                <img src="images/instruct_interpret.png" class="teaser_fig" width="90%">
                <br><br>

                <p class="body_text">
                    The action programs are composed of so-called <strong>"action units"</strong>, which are 3-tuples of
                </p>
            	<center class="body_text"><strong>(part name, joint type, state change)</strong>.</center>
                <p class="body_text">
                    The whole action program should be in one of the following formats
                </p>
                <ul class="body_text">
                	<li class="body_text">a single action unit,</li>
                	<li class="body_text">an unordered union of multiple action units,</li>
                	<li class="body_text">an ordered list of multiple action units,</li>
                </ul>
                <p class="body_text">
                    or be a finite combination of the three formats.
                    Here the <strong>"union"</strong> expression is for non-deterministic policy generation when multiple action units can reach the same goal, e.g. both pulling the door and pressing a button results in the microwave door being opened. <strong>"List"</strong> is for sequential action generation when no single-step solution exists, e.g. in order to open a door, a knob must be first rotated to unlock the door.
                </p>
                
                <p class="body_text">
                    We also incorporate a visual input parser into our instruction interpretation process, which translates the RGB inputs into language descriptions that can be understood by LLMs. A naive solution is to directly employ a VLM to generate scene captions. However, we notice that most of these models lack the capability to provide exact task-related facts. Inspired by prior work, we recognize that the inclusion of expert facts can enhance the correctness of visual perception. Thus, we first detect the actionable parts using the GAPartNet segmentation model for actionable parts, and then pass it into the VLM together with the task description to generate a comprehensive scene description. Combining the expert knowledge of the specialist model and the general knowledge of VLM, we can acquire scene descriptions that are more accurate and also task-relate.
                </p>
                <img src="images/scene_description.png" class="teaser_fig" width="75%">
                <br><br>

                <p class="body_text">
                    We conduct a user study to evaluate the scene descriptions in 6 different aspects. Our method joining the force of domain-specialist models and generalist VLMs achieves the best scores.
                </p>
                <img src="images/result_scene_description.png" class="teaser_fig" width="60%">
                <br><br>
            </div>
        </div>
        </div>
    </section>


	<section class="color_switch">
        <div class="container">
        <div class="row" id="abstract">
            <div class="col my-3">
                <p class="text_header">
                    Part Grounding
                </p>
                
                <p class="body_text">
                    We then convert the action programs defined on the object semantic parts into executable policies through a part grounding module that maps the semantic parts into so-called Generalizable Actionable Parts (GAParts), which is a cross-category definition of parts according to their actionabilities. To achieve this, we employ a large open-vocabulary 2D segmentation model and again combine it with a domain-specialist GAPart model by merging their part proposals and ground them together to GAPart labels.
                </p>
                <img src="images/part_grounding.png" class="teaser_fig" width="80%">
                <br><br>
            </div>
        </div>
        </div>
    </section>


	<section class="color_switch">
        <div class="container">
        <div class="row" id="abstract">
            <div class="col my-3">
                <p class="text_header">
                    Action Generation
                </p>
                
                <p class="body_text">
                    Once we have grounded the semantic part to the actionable part, we can generate executable manipulations on this part. We first estimate the part pose as defined in GAPartNet. We also compute the joint state (part axis and position) and plausible motion direction based on the joint type (prismatic or revolute). Then we generate the part actions according to these estimations. We first predict an initial gripper pose as the primary action. It is followed by a motion induced from a pre-determined strategy defined in GAPartNet according to the part poses and joint states.
                </p>
            </div>
        </div>
        </div>
    </section>

    <section class="color_switch">
        <div class="container">
        <div class="row" id="abstract">
            <div class="col my-3">
                <p class="text_header">
                    Interactive Feedback
                </p>
                
                <p class="body_text">
                     Finally, we also introduce an interactive feedback module that actively responds to failed action steps and adjusts the overall policy accordingly, which enables the framework to act robustly under environmental ambiguities or its own failure.
                </p>
                <img src="images/interactive_feedback.png" class="teaser_fig" width="50%">
                <br><br>
            </div>
        </div>
        </div>
    </section>

    

	<section class="color_switch">
        <div class="container">
        <div class="row" id="abstract">
            <div class="col my-3">
                <p class="text_header">
                    Experiments
                </p>
                <p class="body_text">
                    More interesting demos in our real-world experiments.
                </p>
                <!-- <p class="body_text">
                    We then convert the action programs defined on the object semantic parts into executable policies through a part grounding module that maps the semantic parts into so-called Generalizable Actionable Parts (GAParts), which is a cross-category definition of parts according to their actionabilities. To achieve this, we employ a large open-vocabulary 2D segmentation model and again combine it with a domain-specialist GAPart model by merging their part proposals and ground them together to GAPart labels.
                </p> -->
                <img src="videos/demo_4.gif" class="teaser_fig" width="80%">
                <p class="body_text">
                Leveraging general knowledge from large VLMs and expert knowledge from expert 3D models, our framework has strong generalization capabilities. 
                </p>
                <img src="videos/demo_12.gif" class="teaser_fig" width="80%">
                <br><br>
            </div>
        </div>
        </div>
    </section>


        <div class="row" id="ack" style="margin-top: 1rem">
            <p class="col text_ack my-3">
                If you have any questions, please contact Haoran Geng (ghr@stu.pku.edu.cn).
            </p>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>

    </body>
</html>